# Full Quantification
Fully quantifying a hyperspectrum using the same algorithms that you'd use for a single `Spectrum` takes time.
This example is a 1024 pixel Ã— 1024 pixel hyperspectrum with 2048 channels.  There are 20 elements with 33
distinct fitting regions.  Even on a relatively fast laptop with 64 GB of memory, it takes about 6 hours
to fit and quantify all one million spectra (about 21 ms per particle approximately evenly divided between
fitting and matrix correction.)

However, this is what we will do because sometimes the payoff is worth the pain.  After quantification,
we will end up with a matrix corrected estimate of composition for each pixel in the spectrum image.
We can then cluster on this and extract spectra or mean compositions for each cluster.

The dataset is a cross-section through a deep sea Mn nodule. It has beautiful growth ring structure
which may have deposited over hundreds-of-thousands of years.  There are many elements present somewhere 
in the structure although the material is dominated by Mn, O, C, Si and Fe.  The clustering shows compositional
similarity even at disparite locations on the sample.

First we must load the necesary libraries.
```julia
@warn "This script uses a lot of memory.  It is known to run on a system with 64 GB of RAM and fail with an `OutOfMemoryError` on a system with 16 GB."

using DrWatson
@quickactivate("HyperspectraWithNeXL")
ENV["DATADEPS_ALWAYS_ACCEPT"] = true

using HyperspectraWithNeXL
using NeXLSpectrum # Spectrum, hyperspectrum and fitting
using NeXLMatrixCorrection # Matrix correction
using NeXLParticle # Clustering
using DataFrames # Tabulation
using Images # Display
using FileIO # Saving to disk
using Gadfly #, Cairo, Fontconfig # Plotting
using LinearAlgebra # Normalization
using Statistics # Stats like mean
using Unitful # Adding dimensions to the hyperspectrum axes (fov & offset)
using HDF5 # Support for the HDF5 file type
```

Load the EDS spectrum image from a RPL/RAW file.
```julia
lt = 0.72*4.0*18.0*3600.0/(1024*1024) # 18.0 hours on 4 detectors
hs = NeXLSpectrum.compress(HyperSpectrum(
    LinearEnergyScale(0.0,10.0),
    Dict{Symbol,Any}(
      :TakeOffAngle => deg2rad(35.0),
      :ProbeCurrent => 1.0, # nA
      :LiveTime => lt, 
      :BeamEnergy => 20.0e3, # eV
      :Name => "Mn Nodule"
    ),
    readrplraw(joinpath(datadep"MnNodule","map[15]")), 
    fov = [ 4.096u"mm", 4.096u"mm"], offset= [ 0.0u"mm", 0.0u"mm" ]
))
hs[:Detector] = matching(hs, 132.0)
# hs = hs[1:64:1024,1:64:1024] # Comment this line to run the full spectrum image
hs
```

Create a `FilterFitPacket` with the fitting standards.  Plot the max-pixel spectrum and KLMs from the
reference spectra elements to demonstrate that we've identified the major elements.
```julia; fig_height=3; fig_width=10; fig_ext=".svg";
refpath = datadep"MnNodule_Standards"
refs = references( [
    reference(n"Ag", joinpath(refpath, "Ag std.msa") ),
    reference(n"Al", joinpath(refpath, "Al std.msa") ),
    reference(n"C", joinpath(refpath, "C std.msa") ),
    reference(n"Ca", joinpath(refpath, "CaF2 std.msa") ),
    reference(n"Ce", joinpath(refpath, "CeO2 std.msa") ),
    reference(n"Cl", joinpath(refpath, "NaCl std.msa") ),
    reference(n"Cr", joinpath(refpath, "Cr std.msa") ),
    reference(n"Cu", joinpath(refpath, "Cu std.msa") ),
    reference(n"Fe", joinpath(refpath, "Fe std.msa") ),
    reference(n"S", joinpath(refpath, "FeS2 std.msa") ),
    reference(n"P", joinpath(refpath, "GaP std.msa") ),
    reference(n"K", joinpath(refpath, "KBr std.msa") ),
    reference(n"Mg", joinpath(refpath, "Mg std.msa") ),
    reference(n"O", joinpath(refpath, "MgO std.msa") ),
    reference(n"Mn", joinpath(refpath, "Mn std.msa") ),
    reference(n"Na", joinpath(refpath, "NaCl std.msa") ),
    reference(n"Ni", joinpath(refpath, "Ni std.msa") ),
    reference(n"Si", joinpath(refpath, "Si std.msa") ),
    reference(n"Ti", joinpath(refpath, "Ti std.msa") ),
    reference(n"Zn", joinpath(refpath, "Zn std.msa") ) ], 132.0
)
elems = elms(refs)
# Plot the max-pixel against the reference elements
plot(maxpixel(hs), klms=elems, xmax=10.0e3)
```
Since this calculation can take hours and hours, the results, once calculated, are cached in a HDF5 file
and reloaded rather than recalculated.

Check the cache to see whether we've already computed the result.  If so load it, otherwise compute it.
```julia
resultFile = joinpath(datadir(),"exp_pro","Mn Nodule.hdf5")
mkpath(joinpath(datadir(),"exp_pro"))
qrpath = "Quant Results"
res = if isfile(resultFile)
    @warn "Reading results from the cache."
    h5open(resultFile,"r") do h5
        read(h5, qrpath, Material)
    end
else 
    @warn "Computing k-ratios then mass-fractions. This is likely to take a few hours..." 
    resf = @time fit_spectrum(hs, refs, mode = :Full)
    tmp = @time quantify(resf)
    # Now write the results to the cache
    h5open(resultFile,"w") do h5
        write(h5, qrpath, tmp)
    end
    @info "Quantification results computed and written to cache." 
    tmp
end;
```

`resf` is an `Array{KRatios}` and `res` is an `Array{Material}`.

Look at the statistics on the analytical totals.
```julia
atr = analyticaltotal.(res)
( mean(atr), std(atr), extrema(atr)...)
```

Let's define a function `extract(...)` to extract the mass-fraction associated with `elm`
from an array of `Material`.  This will construct an array the same shape as `mat` but
containing `Float64` representing the mass fraction of `elm`.  When `mats` is normalized
the resulting `Array{Float64}` will only contain values between 0.0 and 1.0 making them
suitable to be gray-scale images in Julia.
```julia
extract(mats::AbstractArray{<:Material}, elm::Element) = map(m->NeXLUncertainties.value(m[elm]), mats)
```

Construct images with various different presentation of the elemental data - a regular gray-scale image, a Mask
of all pixels with mass-fraction of `elm` > 0.1 and a Bright-style Log 3-band image.  Write these to disk as PNG images.
```julia; fig_height=6; fig_width=6; fig_ext=".svg";
output = joinpath(plotsdir(), "Mn Nodule", "Quant")
mkpath(output)
# Convert low analytical totals (maybe voids?) to a null material.
toblack(mat) = analyticaltotal(mat)<0.5 ? NeXLCore.NULL_MATERIAL : mat
# Normalize the mass-fractions to [0.0, 1.0] while setting low totals to zero.
resn = asnormalized.(toblack.(res))
for elm in elems
    elmq = extract(resn, elm)
    # A regular gray-scale image representing each element
    FileIO.save(joinpath(output, "Quant[$(symbol(elm))][Linear].png"), Gray.(elmq))
    # A mask representing each point at which the mass-fraction is greater than 0.1
    FileIO.save(joinpath(output,"Mask[$(symbol(elm)) gt 0.1].png"), Gray.(elmq.>0.1))
    # A Log 3-band image representing the mass fractions
    FileIO.save(joinpath(output, "Quant[$(symbol(elm))][Log3band].png"), Log3Band.(elmq))
end

outpath =joinpath(papersdir(), "Figures", "Figure 10")
mkpath(outpath)
for fn in ( "Quant[C][Log3band].png", "Quant[Cl][Log3band].png", "Quant[Mn][Log3band].png", "Quant[Fe][Log3band].png")
    cp(joinpath(output, fn), joinpath(outpath,fn), force=true)
end

# Construct Log 3-Band images and display them in this document.
for (el, img) in map(el->( symbol(el), Log3Band.(extract(resn, el))), elems)
    display(labeledimage(el,img))
end
```

Construct an RGB colorized view with Mn=>red, C=>green and O=>blue.
```julia; fig_height=6; fig_width=6; fig_ext=".png";
colorview(RGB, extract(resn, n"Mn"), extract(resn,n"C"), extract(resn,n"O"))
```

Cluster on composition rather than k-ratio.
```julia; fig_height=6; fig_width=6; fig_ext=".svg";
els = elems
dv = @time DiluvianCluster(els, map(el->extract(resn, el), els), bin=x->floor(Integer, min(1.0, max(0.0, x)) * 10.0))
climg = asimage(dv)
outpath = joinpath(papersdir(),"Figures","Figure 11")
mkpath(outpath)
FileIO.save(joinpath(outpath, "ClusterMap.png"), climg)
labeledimage("Clustered Compositional Data", climg)
```

```julia; fig_height=2; fig_width=3; fig_ext=".svg";
NeXLParticle.defaultpalette(dv)
```

Construct a ternary to display common types of pixels.
```julia; fig_height=6; fig_width=6; fig_ext=".svg";
# Select those clusters with more than 100 pixels.
cl = collect(filter(i->count(dv,i)>100, eachindex(dv)))
# Draw a multi-ternary diagram to summarize the compositions
mt = multiternary(dv, cl; maxitems = 2500) 
mt |> SVG(joinpath(output,"ClusterTernary.svg"), 8inch, 8inch)
# mt |> PDF(joinpath(outpath,"ClusterTernary.pdf"), 8inch, 8inch)
mt
```

```julia; echo=false
outpath = joinpath(papersdir(),"Figures", "Figure 12")
mkpath(outpath)
cp(joinpath(output,"ClusterTernary.svg"),joinpath(outpath,"ClusterTernary.svg"), force=true)
```

Plot the sum spectrum and a pixel mask. 
```julia; fig_height=3; fig_width=8; fig_ext=".svg";
for i in cl
    # Those pixels in cluster i
    mask = asmask(dv,i)
    # Create a sum spectrum from those pixels
    cs = sum(hs, mask ,name="Cluster $i")
    # Plot the spectrum and the mask
    pai = plotandimage(plot(cs, xmax=10.0e3, klms = elems), Gray.(mask))
    pai |> SVG(joinpath(output,"SaM[Cluster $i].svg"), 8inch, 3inch)
    display(pai)
end
```

```julia; echo=false
# Copy the figures for the paper
for i in 1:4
    cp(joinpath(output,"SaM[Cluster $i].svg"), joinpath(outpath,"SaM[Cluster $i].svg"), force=true)
end 
```

Summarize these classes in a table. `res[asmask(dv,i)]` constructs an array of the `Material`s from the
pixels that are in cluster `i`. Then `mean(...)` takes an array of `Material` and computes the 
average mass-fraction for each element present and returns this as a `Material`.  We will tabulate these
`Material`s for each different cluster in `cl`.
```julia
ENV["columns"]=500
asa(DataFrame, map(i->mean(res[asmask(dv, i)]), cl))
```

##### QED - NWMR 23-Sep-2021